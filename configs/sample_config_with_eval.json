{
    "dataset": "data/sft/sanity.jsonl",
    "output_dir": "models/sft/Qwen/Qwen3-0.6B/batch",
    "tensorboard_dir": "runs/tensorboard/Qwen/Qwen3-0.6B/batch",
    "base_model": "Qwen/Qwen3-0.6B",
    "tokenizer_path": "models/tokenizer/Qwen/Qwen3-0.6B",
    "num_train_steps": 1000,
    "batch_size": 8,
    "grad_accum_steps": 8,
    "learning_rate": 5e-6,
    "max_seq_length": 2048,
    "warmup_ratio": 0.1,
    "max_grad_norm": 1.0,
    "weight_decay": 0.01,
    "lr_scheduler_type": "cosine",
    "fp16": false,
    "bf16": true,
    "use_lora": true,
    "lora_r": 32,
    "lora_alpha": 64,
    "lora_dropout": 0.1,
    "logging_steps": 25,
    "validation_size": 100,
    "checkpoint_steps": 100,
    "gradient_checkpointing": false
}
